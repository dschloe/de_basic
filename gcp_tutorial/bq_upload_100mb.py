from google.cloud import bigquery
import os

# ì„œë¹„ìŠ¤ ê³„ì • í‚¤ ê²½ë¡œ
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "C:/Users/Admin/Desktop/de_basic/gcp_tutorial/lgu6h-project-09e19171e4dd.json"

# BigQuery í´ë¼ì´ì–¸íŠ¸ ìƒì„±
client = bigquery.Client()

# BigQuery í…Œì´ë¸” ì •ë³´
project_id = "lgu6h-project"
dataset_id = "sample_data"
table_id = "creditcard_fraud"
table_ref = f"{project_id}.{dataset_id}.{table_id}"

# ë¡œì»¬ CSV íŒŒì¼ ê²½ë¡œ
file_path = "C:/Users/Admin/Desktop/de_basic/gcp_tutorial/creditcard.csv"

# ìŠ¤í‚¤ë§ˆ ìˆ˜ë™ ì§€ì • (Timeê³¼ Amountì„ í¬í•¨í•œ ëª¨ë“  ì»¬ëŸ¼ì„ FLOAT64ë¡œ ì§€ì •, Classë§Œ INTEGER)
schema = [bigquery.SchemaField("Time", "FLOAT64")] + \
         [bigquery.SchemaField(f"V{i}", "FLOAT64") for i in range(1, 29)] + [
             bigquery.SchemaField("Amount", "FLOAT64"),
             bigquery.SchemaField("Class", "INTEGER"),
         ]

# ì—…ë¡œë“œ ì„¤ì •
job_config = bigquery.LoadJobConfig(
    source_format=bigquery.SourceFormat.CSV,
    skip_leading_rows=1,
    schema=schema
)

# íŒŒì¼ ì—…ë¡œë“œ
with open(file_path, "rb") as source_file:
    load_job = client.load_table_from_file(source_file, table_ref, job_config=job_config)

print("ğŸ“¤ ì—…ë¡œë“œ ì¤‘...")
load_job.result()
print("âœ… ì—…ë¡œë“œ ì™„ë£Œ!")

# ê²°ê³¼ í™•ì¸
table = client.get_table(table_ref)
print(f"ğŸ“Š {table.num_rows} rows loaded to {table.project}.{table.dataset_id}.{table.table_id}")
